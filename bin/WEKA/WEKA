1. clone master branch again from main repo
2. run bin/test.sh
   (if not 100 % success and setting the language to English does not fix this, try on a different system)


3. For EACH .log and .out file (for each test)
   filter out each distinct log level with grep
     find log -name '*.log' -o '*.err' # list of files
   for each file, run (assuming $F is the file)

     grep '^.INFO' $F > $F.info # prefixed
     ...
     grep -v '^\[' $F > $F.raw # non-prefixed

   This will generate about six files for each test case.


DONE

4. Create a line/word list of ALL logs (results of ALL files above),
   > 1000 files, into a word list.
   One "line" list should have unique lines, the other one unique words.
   Probably:
   find ... -name '*.log.*' -o '*.out.*' | xargs cat | sort -u > word-list
   This will give you a line-list. Perhaps this is a good first step to get
   unique lines.
   You can do this similarly on a word level.
   (Perhaps: xargs cat | tr ' ' '\n' | sort -u ...)

5. Histogram analysis: obvious junk/"stop words" to remove?
   This is optional in case there are no absolutely obvious candidates.

6. Map the word list to numbers.
   For example: grep -n ^ word_list # grep for beginning of line, show line no.
   The mapping should be to a consecutive list of integers starting from 0 or 1.

7. Map each filtered log/out file into a record with test ID, word count
   (Check documentation on WEKA preprocessing.)
   Three basic ways:
   1. Boolean (does term X appear in doc Y?)
   2. Word count (how many times does X appear in Y?)
   3. TF-IDF (relative frequency; Y has word X often compared to other docs)

8. Analysis/clustering
   Correlation between attributes on different log channels
   (Look on youtube for clustering with WEKA.)
   Common/rare values (histogram)

9. Also look at scalatest Matchers:
   find ways how to create rule templates for rules that
   1. match a given item
   2. match n-grams (pair, triples) in a given order
   3. multiple items w/o order
   4. contains one (or several) or none of a set of items

10. Analyze the original .log/.err files against occurrences of these patterns
    Which ones are (too) common? Rare?
    Idea: keep rare cases as test oracle.
    Run bin/test.sh but ignore the result.
    Test: if .out/.eout (templates) change, oracle should still pass unless
    functionality changed (look at git log to judge).
